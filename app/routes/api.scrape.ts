import type { LoaderFunctionArgs } from "@remix-run/node";
import { json } from "@remix-run/node";

// This is where you'd import Puppeteer or Playwright in a real scenario
// import puppeteer from 'puppeteer';
// import metascraper from 'metascraper';
// import metascraperImage from 'metascraper-image';
// import metascraperTitle from 'metascraper-title';
// import metascraperDescription from 'metascraper-description';
// import metascraperLogoFavicon from 'metascraper-logo-favicon';

export interface ScrapedData {
  url: string;
  title?: string;
  description?: string;
  imageUrl?: string; // URL of the screenshot
  favicon?: string;
  error?: string;
}

// MOCK IMPLEMENTATION - Replace with actual scraping logic
async function scrapeUrl(targetUrl: string): Promise<ScrapedData> {
  console.log(`API: Mock scraping URL: ${targetUrl}`);
  await new Promise(resolve => setTimeout(resolve, 1500)); // Simulate network delay & processing

  if (!targetUrl.startsWith('http://') && !targetUrl.startsWith('https://')) {
    return { url: targetUrl, error: 'Invalid URL. Please include http:// or https://' };
  }

  try {
    // const browser = await puppeteer.launch(); // Real implementation
    // const page = await browser.newPage();
    // await page.goto(targetUrl, { waitUntil: 'networkidle2', timeout: 15000 });

    // const screenshotBuffer = await page.screenshot({ type: 'png' }); // Real screenshot
    // const imageUrl = `data:image/png;base64,${screenshotBuffer.toString('base64')}`;

    // const htmlContent = await page.content(); // For metadata
    // await browser.close();

    // // Example using metascraper (if installed and imported)
    // const metadata = await metascraper({ html: htmlContent, url: targetUrl, rules: [
    //   metascraperImage(),
    //   metascraperTitle(),
    //   metascraperDescription(),
    //   metascraperLogoFavicon(),
    // ]});

    // Mocked success data:
    const random = Math.random();
    if (random < 0.1) return { url: targetUrl, error: 'Mock API: Failed to load page content.' };
    if (random < 0.2) return { url: targetUrl, error: 'Mock API: Screenshot process timed out.' };

    const hostname = new URL(targetUrl).hostname;

    return {
      url: targetUrl,
      title: `Mock API Title for ${hostname}`,
      description: `This is a mock server-side description for ${targetUrl}. It's generated by the API.`,
      // In a real scenario, imageUrl would be a base64 data URI or a URL to a stored image.
      // Using thum.io for simplicity in mock, but backend should generate its own.
      imageUrl: `https://image.thum.io/get/width/1200/crop/630/${targetUrl}`,
      favicon: `https://www.google.com/s2/favicons?domain=${hostname}&sz=64`,
    };

  } catch (e: any) {
    console.error(`API: Error scraping ${targetUrl}:`, e);
    return { url: targetUrl, error: e.message || 'An unexpected error occurred during scraping on the server.' };
  }
}

export async function loader({ request }: LoaderFunctionArgs) {
  const requestUrl = new URL(request.url);
  const targetUrl = requestUrl.searchParams.get("url");

  if (!targetUrl) {
    return json({ error: "URL parameter is missing" }, { status: 400 });
  }

  try {
    const data = await scrapeUrl(targetUrl);
    if (data.error) {
      // Still return 200, but with error in payload for client to handle
      return json(data);
    }
    return json(data);
  } catch (error) {
    console.error("Scraping loader error:", error);
    return json({ url: targetUrl, error: "Failed to process scraping request." }, { status: 500 });
  }
}
